# Sistema Agentic AI Aut√≥nomo con Tools

## üéØ Arquitectura del Sistema

El sistema ahora est√° compuesto por **agentes verdaderamente aut√≥nomos** que utilizan **LangChain Tools** para tomar decisiones y ejecutar acciones de forma independiente.

### Agentes Aut√≥nomos

#### 1. **AutonomousClassifierAgent**
- **Responsabilidad**: Clasificar la intenci√≥n del usuario
- **LLM**: Gemini 2.5 Flash (comprensi√≥n contextual profunda)
- **Tools Disponibles**:
  - `classify_intent`: Clasificaci√≥n con LLM especializado
  - `get_available_documents_info`: Verificar documentos disponibles
  - `log_agent_decision`: Registrar decisiones
- **Autonom√≠a**: Decide cu√°ndo usar cada tool seg√∫n la complejidad de la consulta

#### 2. **AutonomousRetrieverAgent**
- **Responsabilidad**: Recuperar documentos relevantes
- **LLM**: Groq Llama 3.1 70B (velocidad de recuperaci√≥n)
- **Tools Disponibles**:
  - `search_documents`: B√∫squeda sem√°ntica por similitud
  - `search_documents_by_metadata`: B√∫squeda por filtros
  - `optimize_search_query`: Optimizar queries vagas
  - `log_agent_action`: Registrar acciones
- **Autonom√≠a**: Determina si optimizar la query, cu√°ntos documentos recuperar, y si hacer m√∫ltiples b√∫squedas

#### 3. **AutonomousRAGAgent**
- **Responsabilidad**: Generar respuestas contextuales
- **LLM**: Groq Llama 3.1 70B (generaci√≥n r√°pida)
- **Tools Disponibles**:
  - `generate_rag_response`: Respuesta con documentos
  - `generate_general_response`: Respuesta sin documentos
  - `log_agent_action`: Registrar acciones
- **Autonom√≠a**: Decide qu√© tipo de respuesta generar seg√∫n contexto y adapta el estilo a la intenci√≥n

#### 4. **AutonomousCriticAgent**
- **Responsabilidad**: Validar calidad de respuestas
- **LLM**: Gemini 2.5 Flash (razonamiento profundo)
- **Tools Disponibles**:
  - `validate_response`: Validaci√≥n multi-criterio completa
  - `check_hallucination`: Detecci√≥n de alucinaciones
  - `log_agent_decision`: Registrar decisiones
- **Autonom√≠a**: Decide cu√°ndo hacer an√°lisis profundo de alucinaciones y cu√°ndo aprobar/rechazar respuestas

---

## üõ†Ô∏è Tools de LangChain

### Categor√≠a: B√∫squeda y Recuperaci√≥n

#### `search_documents(query, k, score_threshold)`
Busca documentos en el vector store por similitud sem√°ntica.

**Cu√°ndo usarla**:
- Usuario busca informaci√≥n espec√≠fica
- Se necesita contexto para generar respuesta
- B√∫squeda, resumen o comparaci√≥n

**Par√°metros**:
- `query`: Consulta en lenguaje natural
- `k`: N√∫mero de documentos (3-10 seg√∫n intenci√≥n)
- `score_threshold`: Umbral de relevancia (0.0-1.0)

**Retorna**: Lista de documentos con content, metadata, score

---

#### `search_documents_by_metadata(metadata_filter, k)`
Busca documentos filtrando por metadatos espec√≠ficos.

**Cu√°ndo usarla**:
- Usuario menciona un documento espec√≠fico por nombre
- Se necesita buscar en archivo particular
- Filtrar por autor, fecha, etc.

**Par√°metros**:
- `metadata_filter`: Dict con filtros (ej: `{"source": "doc.pdf"}`)
- `k`: N√∫mero m√°ximo de documentos

**Retorna**: Lista de documentos que coinciden

---

#### `optimize_search_query(query, intent)`
Optimiza una consulta para mejorar recuperaci√≥n.

**Cu√°ndo usarla**:
- Query vaga o ambigua
- Query muy corta (< 5 palabras)
- Se quiere expandir con sin√≥nimos

**Par√°metros**:
- `query`: Consulta original
- `intent`: Tipo de intenci√≥n (busqueda/resumen/comparacion)

**Retorna**: Query optimizada expandida

**Ejemplo**:
```
Input: "diabetes"
Output: "diabetes mellitus tipo 1 tipo 2 s√≠ntomas tratamiento glucosa"
```

---

### Categor√≠a: Generaci√≥n de Respuestas

#### `generate_rag_response(query, documents, intent)`
Genera respuesta basada en documentos recuperados (RAG).

**Cu√°ndo usarla**:
- Hay documentos relevantes disponibles
- Se necesita respuesta con citas
- Intent requiere RAG (busqueda/resumen/comparacion)

**Par√°metros**:
- `query`: Pregunta del usuario
- `documents`: Lista de docs con content y metadata
- `intent`: Adapta estilo (busqueda/resumen/comparacion)

**Retorna**: Respuesta con citas [Fuente X]

---

#### `generate_general_response(query)`
Genera respuesta conversacional sin documentos.

**Cu√°ndo usarla**:
- Consulta conversacional (saludos)
- No requiere informaci√≥n de documentos
- Intent = "general"

**Par√°metros**:
- `query`: Consulta del usuario

**Retorna**: Respuesta directa del LLM

---

### Categor√≠a: Validaci√≥n

#### `validate_response(query, response, context_documents)`
Validaci√≥n completa de respuesta contra fuentes.

**Cu√°ndo usarla**:
- Despu√©s de generar respuesta RAG
- Control de calidad obligatorio
- Antes de entregar respuesta al usuario

**Par√°metros**:
- `query`: Pregunta original
- `response`: Respuesta generada
- `context_documents`: Docs usados para generar

**Retorna**:
```python
{
    "is_valid": bool,
    "confidence_score": float,  # 0-1
    "issues": List[str],
    "recommendations": str
}
```

**Criterios evaluados**:
1. Coherencia estructural (20%)
2. Alineaci√≥n con fuentes (30%)
3. Ausencia de alucinaciones (25%)
4. Completitud (15%)
5. Calidad de citas (10%)

---

#### `check_hallucination(response, context_documents)`
An√°lisis espec√≠fico de alucinaciones.

**Cu√°ndo usarla**:
- validate_response detect√≥ problemas
- Se necesita an√°lisis profundo
- Dudas sobre fidelidad a fuentes

**Par√°metros**:
- `response`: Respuesta a verificar
- `context_documents`: Documentos fuente

**Retorna**:
```python
{
    "has_hallucination": bool,
    "hallucination_score": float,  # 0=sin, 1=graves
    "problematic_claims": List[str],
    "analysis": str
}
```

---

### Categor√≠a: Clasificaci√≥n

#### `classify_intent(query)`
Clasifica intenci√≥n del usuario en 4 categor√≠as.

**Cu√°ndo usarla**:
- Primera etapa de procesamiento
- Consulta nueva del usuario
- Determinar estrategia de respuesta

**Par√°metros**:
- `query`: Consulta en lenguaje natural

**Retorna**:
```python
{
    "intent": str,  # busqueda/resumen/comparacion/general
    "confidence": float,  # 0-1
    "requires_rag": bool,
    "reasoning": str
}
```

**Categor√≠as**:
- **busqueda**: Informaci√≥n espec√≠fica de documentos
- **resumen**: Sintetizar documentos
- **comparacion**: Contrastar conceptos
- **general**: Conversaci√≥n sin RAG

---

### Categor√≠a: Logging y Trazabilidad

#### `log_agent_decision(agent_name, decision, reasoning, metadata)`
Registra decisiones de agentes para trazabilidad.

**Cu√°ndo usarla**:
- Agente toma decisi√≥n importante
- Se necesita auditar comportamiento
- Crear historial de razonamiento

**Par√°metros**:
- `agent_name`: Nombre del agente
- `decision`: Decisi√≥n tomada
- `reasoning`: Justificaci√≥n
- `metadata`: Info adicional (opcional)

**Retorna**: Confirmaci√≥n con timestamp

---

#### `log_agent_action(agent_name, action, input_data, output_data, success)`
Registra acciones ejecutadas por agentes.

**Cu√°ndo usarla**:
- Agente ejecuta acci√≥n concreta
- Rastrear flujo de datos
- Debugging y an√°lisis

**Par√°metros**:
- `agent_name`: Nombre del agente
- `action`: Acci√≥n ejecutada
- `input_data`: Entrada (resumida)
- `output_data`: Salida (resumida)
- `success`: Si fue exitosa (default: True)

**Retorna**: Confirmaci√≥n con timestamp

---

#### `get_available_documents_info()`
Informaci√≥n sobre documentos indexados.

**Cu√°ndo usarla**:
- Usuario pregunta qu√© hay disponible
- Verificar si sistema tiene contenido
- Info sobre el corpus

**Retorna**:
```python
{
    "total_documents": int,
    "status": str,
    "message": str
}
```

---

## üìä Flujo del Sistema Aut√≥nomo

```
Usuario ‚Üí "¬øQu√© es la diabetes tipo 2?"
    ‚Üì
[1] ClassifierAgent (con tools)
    ‚Üí classify_intent("¬øQu√© es la diabetes tipo 2?")
    ‚Üí log_agent_decision(...)
    ‚Üì intent="busqueda", requires_rag=True
    
[2] RetrieverAgent (con tools)
    ‚Üí optimize_search_query(query, "busqueda")  [decide si necesario]
    ‚Üí search_documents(query_optimizada, k=4)
    ‚Üí log_agent_action(...)
    ‚Üì 4 documentos recuperados
    
[3] RAGAgent (con tools)
    ‚Üí generate_rag_response(query, docs, "busqueda")
    ‚Üí log_agent_action(...)
    ‚Üì Respuesta generada con citas
    
[4] CriticAgent (con tools)
    ‚Üí validate_response(query, response, docs)
    ‚Üí check_hallucination(response, docs)  [si hay dudas]
    ‚Üí log_agent_decision(...)
    ‚Üì 
    - Si v√°lida ‚Üí Entregar respuesta
    - Si inv√°lida ‚Üí Regenerar (max 2 veces)
    
Usuario ‚Üê Respuesta final + trazabilidad completa
```

---

## üîß Uso de los Agentes Aut√≥nomos

### Ejemplo 1: Uso B√°sico

```python
from src.agents.autonomous_orchestrator import AutonomousOrchestrator

# Inicializar orquestador (carga todos los agentes)
orchestrator = AutonomousOrchestrator()

# Procesar consulta (agentes deciden qu√© tools usar)
result = orchestrator.process_query("¬øQu√© es el COVID-19?")

print(result["response"])
print(f"Intenci√≥n: {result['intent']}")
print(f"Documentos usados: {result['documents_used']}")
print(f"Validaci√≥n: {result['validation']['confidence_score']:.2f}")
print(f"Tools usadas: {result['trace']['tools_used']}")
```

### Ejemplo 2: Uso Individual de Agentes

```python
from src.agents.autonomous_classifier_agent import AutonomousClassifierAgent

# Agente individual (decide cu√°ndo usar tools)
classifier = AutonomousClassifierAgent()

# El agente analiza y decide si usar classify_intent tool
classification = classifier.classify("Compara diabetes tipo 1 y 2")

print(f"Intenci√≥n: {classification['intent']}")
print(f"Razonamiento: {classification['reasoning']}")
print(f"Pasos intermedios: {len(classification['intermediate_steps'])}")
```

### Ejemplo 3: Trazabilidad Completa

```python
result = orchestrator.process_query("Resume el art√≠culo sobre diabetes")

# Ver todos los pasos
for step in result["trace"]["steps"]:
    print(f"Paso {step['step']}: {step['agent']} - {step['action']}")
    print(f"  Resultado: {step['result']}")

# Ver agentes llamados
print(f"Agentes: {result['trace']['agents_called']}")

# Ver tools usadas
print(f"Tools: {result['trace']['tools_used']}")
```

---

## üéì Ventajas del Sistema Aut√≥nomo

### ‚úÖ Antes (Sistema Guiado)
- C√≥digo Python decide cada paso
- Agentes ejecutan √≥rdenes predefinidas
- Flujo r√≠gido y predecible
- Sin adaptaci√≥n a contexto

### ‚ú® Ahora (Sistema Aut√≥nomo)
- **Agentes toman decisiones**: Cada agente razona qu√© hacer
- **Tools bajo demanda**: Usan tools cuando lo necesitan
- **Flujo adaptativo**: Se ajusta al contexto de cada consulta
- **Trazabilidad real**: Se ve exactamente qu√© decidi√≥ cada agente

### Ejemplo de Autonom√≠a

**Query vaga**: "covid"

```
RetrieverAgent decide:
1. "Query muy corta, necesito optimizarla"
2. Usa: optimize_search_query("covid", "busqueda")
3. Query optimizada: "covid-19 coronavirus s√≠ntomas tratamiento"
4. Usa: search_documents(query_optimizada, k=4)
5. Registra: log_agent_action(...)
```

**Query clara**: "¬øCu√°les son los s√≠ntomas del COVID-19?"

```
RetrieverAgent decide:
1. "Query espec√≠fica y clara, no necesito optimizar"
2. Usa directamente: search_documents(query, k=4)
3. Registra: log_agent_action(...)
```

---

## üìã Checklist de Implementaci√≥n

- [x] Convertir tools existentes a formato `@tool` de LangChain
- [x] Crear nuevas tools √∫tiles (11 total)
- [x] Documentaci√≥n detallada en docstrings de cada tool
- [x] Agente Clasificador Aut√≥nomo con tools
- [x] Agente Recuperador Aut√≥nomo con tools
- [x] Agente RAG Aut√≥nomo con tools
- [x] Agente Cr√≠tico Aut√≥nomo con tools
- [x] Orquestador que coordina agentes aut√≥nomos
- [x] Sistema de trazabilidad completo
- [x] Documentaci√≥n de tools y agentes

---

## üöÄ Pr√≥ximos Pasos

1. **Probar el sistema aut√≥nomo** con consultas variadas
2. **Ajustar prompts** de agentes seg√∫n resultados
3. **Agregar m√°s tools** si se identifican necesidades
4. **Optimizar decisiones** de agentes basado en logs
5. **Documentar casos de uso** en informe t√©cnico

---

## üìö Referencias

- [LangChain Tools Documentation](https://python.langchain.com/docs/modules/tools/)
- [LangChain Agents](https://python.langchain.com/docs/modules/agents/)
- [Tool Calling with Gemini](https://ai.google.dev/gemini-api/docs/function-calling)
- [Groq API Documentation](https://console.groq.com/docs)
