"""
Test de Cumplimiento de Requisitos - Pr√°ctica 2 PLN
=====================================================

Este script valida que el sistema cumple con TODOS los requisitos espec√≠ficos
definidos en el enunciado de la pr√°ctica.

Requisitos a validar:
- 5+ agentes funcionales con LangChain 1.0
- Agente Indexador (consumo, limpieza, chunking, embeddings, vector store)
- Agente Clasificador (4 tipos de consultas, usa LLM apropiado)
- Agente Recuperador (b√∫squeda sem√°ntica, usa LLM para optimizaci√≥n)
- Agente RAG (genera respuestas con citas, usa LLM r√°pido)
- Agente Cr√≠tico (valida coherencia/alucinaciones, usa LLM de razonamiento)
- 5+ herramientas (Tools) implementadas
- Trazabilidad de decisiones y rutas
- 100+ documentos procesados
- Uso diferenciado de Gemini y Groq con justificaci√≥n
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv
from typing import Dict, List, Any

# Cargar variables de entorno
load_dotenv()

# Colores para terminal
class Colors:
    GREEN = '\033[92m'
    RED = '\033[91m'
    YELLOW = '\033[93m'
    BLUE = '\033[94m'
    BOLD = '\033[1m'
    END = '\033[0m'

def print_header(text: str):
    """Imprime un encabezado formateado."""
    print(f"\n{Colors.BOLD}{Colors.BLUE}{'='*80}{Colors.END}")
    print(f"{Colors.BOLD}{Colors.BLUE}{text:^80}{Colors.END}")
    print(f"{Colors.BOLD}{Colors.BLUE}{'='*80}{Colors.END}\n")

def print_test(name: str, passed: bool, details: str = ""):
    """Imprime resultado de una prueba."""
    status = f"{Colors.GREEN}‚úÖ PASS{Colors.END}" if passed else f"{Colors.RED}‚ùå FAIL{Colors.END}"
    print(f"{status} | {name}")
    if details:
        print(f"       {Colors.YELLOW}{details}{Colors.END}")

def print_summary(passed: int, total: int):
    """Imprime resumen final."""
    percentage = (passed / total * 100) if total > 0 else 0
    color = Colors.GREEN if percentage == 100 else Colors.YELLOW if percentage >= 80 else Colors.RED
    print(f"\n{Colors.BOLD}{color}{'='*80}{Colors.END}")
    print(f"{Colors.BOLD}{color}RESUMEN: {passed}/{total} pruebas pasaron ({percentage:.1f}%){Colors.END}")
    print(f"{Colors.BOLD}{color}{'='*80}{Colors.END}\n")

# ============================================================================
# TEST 1: OBJETIVO ESPEC√çFICO 1
# Dise√±ar e implementar un flujo Agentic AI multi-agente con al menos 5 agentes
# ============================================================================

def test_objective_1():
    """Valida que existen al menos 5 agentes funcionales con LangChain 1.0."""
    print_header("OBJETIVO 1: Sistema Multi-Agente (‚â•5 agentes)")
    
    results = []
    
    # Test 1.1: Importar agentes aut√≥nomos
    try:
        from src.agents import (
            AutonomousClassifierAgent,
            AutonomousRetrieverAgent,
            AutonomousRAGAgent,
            AutonomousCriticAgent,
            AutonomousOrchestrator,
            AutonomousIndexerAgent
        )
        results.append(("Importaci√≥n de 6 agentes aut√≥nomos", True, "Classifier, Retriever, RAG, Critic, Orchestrator, Indexer"))
    except Exception as e:
        results.append(("Importaci√≥n de agentes", False, f"Error: {str(e)}"))
        return results
    
    # Test 1.2: Verificar que usan LangChain 1.0 (langgraph)
    try:
        from src.agents.autonomous_classifier_agent import AutonomousClassifierAgent
        import inspect
        # Verificar en el archivo fuente directamente
        import pathlib
        file_path = pathlib.Path("src/agents/autonomous_classifier_agent.py")
        if file_path.exists():
            source_code = file_path.read_text(encoding='utf-8')
            uses_langgraph = "from langgraph.prebuilt import create_react_agent" in source_code
        else:
            source = inspect.getsource(AutonomousClassifierAgent)
            uses_langgraph = "langgraph" in source and "create_react_agent" in source
        
        results.append(("Uso de LangChain 1.0 (langgraph)", uses_langgraph, 
                       "Usa create_react_agent de langgraph.prebuilt" if uses_langgraph else "No usa la API correcta"))
    except Exception as e:
        results.append(("Verificaci√≥n API LangChain", False, f"Error: {str(e)}"))
    
    # Test 1.3: Inicializar todos los agentes
    try:
        classifier = AutonomousClassifierAgent()
        retriever = AutonomousRetrieverAgent()
        rag = AutonomousRAGAgent()
        critic = AutonomousCriticAgent()
        indexer = AutonomousIndexerAgent()
        orchestrator = AutonomousOrchestrator()
        
        results.append(("Inicializaci√≥n de 6 agentes", True, "Todos los agentes se inicializan sin errores"))
    except Exception as e:
        results.append(("Inicializaci√≥n de agentes", False, f"Error: {str(e)}"))
    
    # Test 1.4: Verificar que tienen agent_executor (langgraph)
    try:
        has_executors = all([
            hasattr(classifier, 'agent_executor'),
            hasattr(retriever, 'agent_executor'),
            hasattr(rag, 'agent_executor'),
            hasattr(critic, 'agent_executor'),
            hasattr(indexer, 'agent_executor')
        ])
        results.append(("Agentes tienen executor de langgraph", has_executors,
                       "Todos los agentes tienen agent_executor" if has_executors else "Falta agent_executor en alg√∫n agente"))
    except Exception as e:
        results.append(("Verificaci√≥n executors", False, f"Error: {str(e)}"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 2: OBJETIVO ESPEC√çFICO 2
# Agente especializado para consumo, limpieza, chunking e indexaci√≥n
# ============================================================================

def test_objective_2():
    """Valida el agente indexador completo."""
    print_header("OBJETIVO 2: Agente Indexador Especializado")
    
    results = []
    
    # Test 2.1: Verificar herramientas de carga de documentos
    try:
        from src.tools import (
            load_document,
            scan_directory_for_documents,
            load_documents_batch
        )
        results.append(("Tools de carga de documentos", True, "load_document, scan_directory, load_batch"))
    except Exception as e:
        results.append(("Tools de carga", False, f"Error: {str(e)}"))
    
    # Test 2.2: Verificar herramientas de procesamiento
    try:
        from src.tools import (
            clean_documents,
            chunk_documents,
            process_documents_pipeline
        )
        results.append(("Tools de procesamiento", True, "clean_documents, chunk_documents, pipeline"))
    except Exception as e:
        results.append(("Tools de procesamiento", False, f"Error: {str(e)}"))
    
    # Test 2.3: Verificar herramientas de indexaci√≥n
    try:
        from src.tools import (
            create_vector_index,
            add_to_vector_index,
            save_vector_index,
            load_vector_index,
            get_index_statistics
        )
        results.append(("Tools de indexaci√≥n (Vector Store)", True, "create, add, save, load, stats"))
    except Exception as e:
        results.append(("Tools de indexaci√≥n", False, f"Error: {str(e)}"))
    
    # Test 2.4: Verificar que AutonomousIndexerAgent tiene todas las tools
    try:
        from src.agents import AutonomousIndexerAgent
        indexer = AutonomousIndexerAgent()
        
        # Verificar que tiene las 11-13 tools esperadas
        tool_count = len(indexer.tools)
        has_enough_tools = tool_count >= 11
        
        results.append(("IndexerAgent con herramientas completas", has_enough_tools,
                       f"{tool_count} tools asignadas (‚â•11 requeridas)"))
    except Exception as e:
        results.append(("IndexerAgent con tools", False, f"Error: {str(e)}"))
    
    # Test 2.5: Verificar m√©todos del agente
    try:
        from src.agents import AutonomousIndexerAgent
        indexer = AutonomousIndexerAgent()
        
        has_methods = all([
            hasattr(indexer, 'index_directory'),
            hasattr(indexer, 'add_documents'),
            hasattr(indexer, 'load_existing_index'),
            hasattr(indexer, 'get_stats')
        ])
        
        results.append(("IndexerAgent con m√©todos funcionales", has_methods,
                       "index_directory, add_documents, load_existing_index, get_stats"))
    except Exception as e:
        results.append(("M√©todos del IndexerAgent", False, f"Error: {str(e)}"))
    
    # Test 2.6: Verificar uso de embeddings
    try:
        from src.rag_pipeline.embeddings import EmbeddingsManager
        embeddings = EmbeddingsManager()
        
        # Verificar que puede generar embeddings
        test_text = "Este es un texto de prueba"
        embedding = embeddings.embed_query(test_text)
        
        is_valid = isinstance(embedding, list) and len(embedding) > 0
        results.append(("Generaci√≥n de embeddings funcional", is_valid,
                       f"Dimensi√≥n: {len(embedding)}" if is_valid else "Error generando embeddings"))
    except Exception as e:
        results.append(("Embeddings", False, f"Error: {str(e)}"))
    
    # Test 2.7: Verificar uso de FAISS
    try:
        from src.rag_pipeline.vectorstore import VectorStoreManager
        results.append(("FAISS Vector Store disponible", True, "VectorStoreManager importado correctamente"))
    except Exception as e:
        results.append(("FAISS Vector Store", False, f"Error: {str(e)}"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 3: OBJETIVO ESPEC√çFICO 3
# Agente clasificador de intenci√≥n (4 tipos de consultas)
# ============================================================================

def test_objective_3():
    """Valida el agente clasificador y sus capacidades."""
    print_header("OBJETIVO 3: Agente Clasificador (4 tipos de consultas)")
    
    results = []
    
    # Test 3.1: Verificar que existe el agente clasificador
    try:
        from src.agents import AutonomousClassifierAgent
        classifier = AutonomousClassifierAgent()
        results.append(("Agente Clasificador existe", True, "AutonomousClassifierAgent inicializado"))
    except Exception as e:
        results.append(("Agente Clasificador", False, f"Error: {str(e)}"))
        return results
    
    # Test 3.2: Verificar que tiene el m√©todo classify
    try:
        has_classify = hasattr(classifier, 'classify')
        results.append(("M√©todo classify() disponible", has_classify,
                       "M√©todo classify presente" if has_classify else "Falta m√©todo classify"))
    except Exception as e:
        results.append(("M√©todo classify", False, f"Error: {str(e)}"))
    
    # Test 3.3: Verificar que tiene herramientas de clasificaci√≥n
    try:
        tool_names = [tool.name for tool in classifier.tools]
        has_classify_tool = "classify_intent" in tool_names
        results.append(("Tool classify_intent disponible", has_classify_tool,
                       f"Tools: {', '.join(tool_names)}" if has_classify_tool else "Falta classify_intent"))
    except Exception as e:
        results.append(("Tools del clasificador", False, f"Error: {str(e)}"))
    
    # Test 3.4: Verificar que usa un LLM apropiado (Gemini para razonamiento profundo)
    try:
        from src.config.llm_config import llm_config
        classifier_llm = llm_config.get_classifier_llm()
        llm_name = str(type(classifier_llm).__name__)
        uses_gemini = "Gemini" in llm_name or "ChatGoogleGenerativeAI" in llm_name
        
        results.append(("Usa LLM apropiado (Gemini)", uses_gemini,
                       f"LLM: {llm_name}" if uses_gemini else f"Usa {llm_name} - se esperaba Gemini"))
    except Exception as e:
        results.append(("LLM del clasificador", False, f"Error: {str(e)}"))
    
    # Test 3.5: Verificar prompt del clasificador menciona 4 categor√≠as
    try:
        prompt_text = str(classifier.prompt)
        has_busqueda = "busqueda" in prompt_text.lower() or "b√∫squeda" in prompt_text.lower()
        has_resumen = "resumen" in prompt_text.lower()
        has_comparacion = "comparacion" in prompt_text.lower() or "comparaci√≥n" in prompt_text.lower()
        has_general = "general" in prompt_text.lower()
        
        all_categories = has_busqueda and has_resumen and has_comparacion and has_general
        categories_found = []
        if has_busqueda: categories_found.append("b√∫squeda")
        if has_resumen: categories_found.append("resumen")
        if has_comparacion: categories_found.append("comparaci√≥n")
        if has_general: categories_found.append("general")
        
        results.append(("Prompt menciona 4 categor√≠as", all_categories,
                       f"Categor√≠as: {', '.join(categories_found)}" if all_categories else f"Faltan categor√≠as: {4 - len(categories_found)}"))
    except Exception as e:
        results.append(("Prompt del clasificador", False, f"Error: {str(e)}"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 4: OBJETIVO ESPEC√çFICO 4
# Agente recuperador sem√°ntico
# ============================================================================

def test_objective_4():
    """Valida el agente recuperador."""
    print_header("OBJETIVO 4: Agente Recuperador Sem√°ntico")
    
    results = []
    
    # Test 4.1: Verificar que existe el agente recuperador
    try:
        from src.agents import AutonomousRetrieverAgent
        retriever = AutonomousRetrieverAgent()
        results.append(("Agente Recuperador existe", True, "AutonomousRetrieverAgent inicializado"))
    except Exception as e:
        results.append(("Agente Recuperador", False, f"Error: {str(e)}"))
        return results
    
    # Test 4.2: Verificar que tiene m√©todo retrieve
    try:
        has_retrieve = hasattr(retriever, 'retrieve')
        results.append(("M√©todo retrieve() disponible", has_retrieve,
                       "M√©todo retrieve presente" if has_retrieve else "Falta m√©todo retrieve"))
    except Exception as e:
        results.append(("M√©todo retrieve", False, f"Error: {str(e)}"))
    
    # Test 4.3: Verificar herramientas de recuperaci√≥n
    try:
        tool_names = [tool.name for tool in retriever.tools]
        has_retrieve_tool = "retrieve_documents" in tool_names or "search_documents" in tool_names
        results.append(("Tools de b√∫squeda disponibles", has_retrieve_tool,
                       f"Tools: {', '.join(tool_names)}"))
    except Exception as e:
        results.append(("Tools del recuperador", False, f"Error: {str(e)}"))
    
    # Test 4.4: Verificar que usa LLM para optimizaci√≥n (Groq para velocidad)
    try:
        from src.config.llm_config import llm_config
        retriever_llm = llm_config.get_retriever_llm()
        llm_name = str(type(retriever_llm).__name__)
        uses_groq = "Groq" in llm_name or "ChatGroq" in llm_name
        
        results.append(("Usa LLM apropiado (Groq)", uses_groq,
                       f"LLM: {llm_name}" if uses_groq else f"Usa {llm_name} - se esperaba Groq"))
    except Exception as e:
        results.append(("LLM del recuperador", False, f"Error: {str(e)}"))
    
    # Test 4.5: Verificar b√∫squeda sem√°ntica basada en embeddings
    try:
        prompt_text = str(retriever.prompt)
        mentions_semantic = "semantic" in prompt_text.lower() or "sem√°ntic" in prompt_text.lower()
        mentions_embeddings = "embedding" in prompt_text.lower()
        
        results.append(("B√∫squeda sem√°ntica configurada", mentions_semantic or mentions_embeddings,
                       "Prompt menciona b√∫squeda sem√°ntica/embeddings" if (mentions_semantic or mentions_embeddings) else "Prompt no menciona b√∫squeda sem√°ntica"))
    except Exception as e:
        results.append(("Configuraci√≥n sem√°ntica", False, f"Error: {str(e)}"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 5: OBJETIVO ESPEC√çFICO 5
# Agente generador de respuestas mediante RAG
# ============================================================================

def test_objective_5():
    """Valida el agente RAG."""
    print_header("OBJETIVO 5: Agente Generador RAG")
    
    results = []
    
    # Test 5.1: Verificar que existe el agente RAG
    try:
        from src.agents import AutonomousRAGAgent
        rag = AutonomousRAGAgent()
        results.append(("Agente RAG existe", True, "AutonomousRAGAgent inicializado"))
    except Exception as e:
        results.append(("Agente RAG", False, f"Error: {str(e)}"))
        return results
    
    # Test 5.2: Verificar que tiene m√©todo generate
    try:
        has_generate = hasattr(rag, 'generate')
        results.append(("M√©todo generate() disponible", has_generate,
                       "M√©todo generate presente" if has_generate else "Falta m√©todo generate"))
    except Exception as e:
        results.append(("M√©todo generate", False, f"Error: {str(e)}"))
    
    # Test 5.3: Verificar herramientas de generaci√≥n
    try:
        tool_names = [tool.name for tool in rag.tools]
        has_generate_tool = "generate_response" in tool_names or "generate_rag_response" in tool_names
        results.append(("Tools de generaci√≥n disponibles", has_generate_tool,
                       f"Tools: {', '.join(tool_names)}"))
    except Exception as e:
        results.append(("Tools del RAG", False, f"Error: {str(e)}"))
    
    # Test 5.4: Verificar que usa LLM r√°pido (Groq)
    try:
        from src.config.llm_config import llm_config
        rag_llm = llm_config.get_rag_llm()
        llm_name = str(type(rag_llm).__name__)
        uses_groq = "Groq" in llm_name or "ChatGroq" in llm_name
        
        results.append(("Usa LLM apropiado (Groq)", uses_groq,
                       f"LLM: {llm_name}" if uses_groq else f"Usa {llm_name} - se esperaba Groq"))
    except Exception as e:
        results.append(("LLM del RAG", False, f"Error: {str(e)}"))
    
    # Test 5.5: Verificar que menciona citas en el prompt
    try:
        prompt_text = str(rag.prompt)
        mentions_citations = "cita" in prompt_text.lower() or "citation" in prompt_text.lower() or "fuente" in prompt_text.lower()
        
        results.append(("Genera respuestas con citas", mentions_citations,
                       "Prompt menciona citas/fuentes" if mentions_citations else "Prompt no menciona citas"))
    except Exception as e:
        results.append(("Configuraci√≥n de citas", False, f"Error: {str(e)}"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 6: OBJETIVO ESPEC√çFICO 6
# Agente cr√≠tico/verificador
# ============================================================================

def test_objective_6():
    """Valida el agente cr√≠tico."""
    print_header("OBJETIVO 6: Agente Cr√≠tico/Verificador")
    
    results = []
    
    # Test 6.1: Verificar que existe el agente cr√≠tico
    try:
        from src.agents import AutonomousCriticAgent
        critic = AutonomousCriticAgent()
        results.append(("Agente Cr√≠tico existe", True, "AutonomousCriticAgent inicializado"))
    except Exception as e:
        results.append(("Agente Cr√≠tico", False, f"Error: {str(e)}"))
        return results
    
    # Test 6.2: Verificar que tiene m√©todo validate
    try:
        has_validate = hasattr(critic, 'validate')
        results.append(("M√©todo validate() disponible", has_validate,
                       "M√©todo validate presente" if has_validate else "Falta m√©todo validate"))
    except Exception as e:
        results.append(("M√©todo validate", False, f"Error: {str(e)}"))
    
    # Test 6.3: Verificar herramientas de validaci√≥n
    try:
        tool_names = [tool.name for tool in critic.tools]
        has_validate_tool = "validate_response" in tool_names
        results.append(("Tool validate_response disponible", has_validate_tool,
                       f"Tools: {', '.join(tool_names)}"))
    except Exception as e:
        results.append(("Tools del cr√≠tico", False, f"Error: {str(e)}"))
    
    # Test 6.4: Verificar que usa LLM apropiado (Gemini para razonamiento)
    try:
        from src.config.llm_config import llm_config
        critic_llm = llm_config.get_critic_llm()
        llm_name = str(type(critic_llm).__name__)
        uses_gemini = "Gemini" in llm_name or "ChatGoogleGenerativeAI" in llm_name
        
        results.append(("Usa LLM apropiado (Gemini)", uses_gemini,
                       f"LLM: {llm_name}" if uses_gemini else f"Usa {llm_name} - se esperaba Gemini"))
    except Exception as e:
        results.append(("LLM del cr√≠tico", False, f"Error: {str(e)}"))
    
    # Test 6.5: Verificar que el prompt menciona validaci√≥n de alucinaciones
    try:
        prompt_text = str(critic.prompt)
        mentions_hallucination = "alucinacion" in prompt_text.lower() or "hallucination" in prompt_text.lower()
        mentions_coherence = "coherencia" in prompt_text.lower() or "coherence" in prompt_text.lower()
        mentions_context = "contexto" in prompt_text.lower() or "context" in prompt_text.lower()
        
        all_aspects = mentions_hallucination and mentions_coherence and mentions_context
        aspects_found = []
        if mentions_hallucination: aspects_found.append("alucinaciones")
        if mentions_coherence: aspects_found.append("coherencia")
        if mentions_context: aspects_found.append("contexto")
        
        results.append(("Valida alucinaciones/coherencia/contexto", all_aspects,
                       f"Aspectos: {', '.join(aspects_found)}" if aspects_found else "No menciona aspectos de validaci√≥n"))
    except Exception as e:
        results.append(("Configuraci√≥n de validaci√≥n", False, f"Error: {str(e)}"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 7: OBJETIVO ESPEC√çFICO 7
# Al menos 5 herramientas (Tools) implementadas
# ============================================================================

def test_objective_7():
    """Valida que hay al menos 5 tools implementadas."""
    print_header("OBJETIVO 7: Herramientas (Tools) ‚â•5")
    
    results = []
    
    # Test 7.1: Contar todas las tools disponibles
    try:
        from src.tools import ALL_LANGCHAIN_TOOLS
        tool_count = len(ALL_LANGCHAIN_TOOLS)
        has_enough = tool_count >= 5
        
        results.append(("Total de Tools disponibles", has_enough,
                       f"{tool_count} tools (‚â•5 requeridas)"))
    except Exception as e:
        results.append(("Total de Tools", False, f"Error: {str(e)}"))
    
    # Test 7.2: Verificar tools de query processing
    try:
        from src.tools import (
            classify_intent,
            search_documents,  # O retrieve_documents
            generate_rag_response,  # O generate_response
            validate_response,
            optimize_search_query  # O optimize_query
        )
        results.append(("Tools de query processing", True, 
                       "classify_intent, search_documents, generate_rag_response, validate_response, optimize_search_query"))
    except Exception as e:
        results.append(("Tools de query", False, f"Error: {str(e)}"))
    
    # Test 7.3: Verificar tools de indexing
    try:
        from src.tools import (
            load_document,
            clean_documents,
            chunk_documents,
            create_vector_index,
            save_vector_index
        )
        results.append(("Tools de indexing", True,
                       "load_document, clean_documents, chunk_documents, create_vector_index, save_vector_index"))
    except Exception as e:
        results.append(("Tools de indexing", False, f"Error: {str(e)}"))
    
    # Test 7.4: Verificar que las tools usan el decorador @tool de LangChain
    try:
        from src.tools import classify_intent
        has_langchain_decorator = hasattr(classify_intent, 'name') and hasattr(classify_intent, 'description')
        
        results.append(("Tools usan decorador @tool de LangChain", has_langchain_decorator,
                       "Tools tienen name y description" if has_langchain_decorator else "No usan @tool correctamente"))
    except Exception as e:
        results.append(("Decorador @tool", False, f"Error: {str(e)}"))
    
    # Test 7.5: Listar todas las tools por categor√≠a
    try:
        from src.tools import ALL_LANGCHAIN_TOOLS, INDEXER_TOOLS
        
        query_tools = [t for t in ALL_LANGCHAIN_TOOLS if t not in INDEXER_TOOLS]
        
        print(f"\n       {Colors.BLUE}üìã INVENTARIO DE TOOLS:{Colors.END}")
        print(f"       {Colors.BLUE}‚îú‚îÄ Query Processing: {len(query_tools)} tools{Colors.END}")
        for tool in query_tools[:5]:  # Mostrar primeras 5
            print(f"       {Colors.BLUE}‚îÇ  ‚Ä¢ {tool.name}{Colors.END}")
        if len(query_tools) > 5:
            print(f"       {Colors.BLUE}‚îÇ  ‚Ä¢ ... y {len(query_tools)-5} m√°s{Colors.END}")
        
        print(f"       {Colors.BLUE}‚îî‚îÄ Indexing: {len(INDEXER_TOOLS)} tools{Colors.END}")
        for tool in INDEXER_TOOLS[:5]:  # Mostrar primeras 5
            print(f"       {Colors.BLUE}   ‚Ä¢ {tool.name}{Colors.END}")
        if len(INDEXER_TOOLS) > 5:
            print(f"       {Colors.BLUE}   ‚Ä¢ ... y {len(INDEXER_TOOLS)-5} m√°s{Colors.END}")
        
        results.append(("Inventario de tools completo", True,
                       f"{len(ALL_LANGCHAIN_TOOLS)} tools totales"))
    except Exception as e:
        results.append(("Inventario de tools", False, f"Error: {str(e)}"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 8: OBJETIVO ESPEC√çFICO 8
# Mecanismos de trazabilidad
# ============================================================================

def test_objective_8():
    """Valida mecanismos de trazabilidad."""
    print_header("OBJETIVO 8: Trazabilidad")
    
    results = []
    
    # Test 8.1: Verificar que existe tool de logging
    try:
        from src.tools import log_agent_decision
        results.append(("Tool log_agent_decision disponible", True, "Herramienta de logging presente"))
    except Exception as e:
        results.append(("Tool de logging", False, f"Error: {str(e)}"))
    
    # Test 8.2: Verificar que orchestrator tiene m√©todo de trace
    try:
        from src.agents import AutonomousOrchestrator
        orchestrator = AutonomousOrchestrator()
        has_trace = hasattr(orchestrator, 'process_query') or hasattr(orchestrator, 'orchestrate')
        
        results.append(("Orchestrator con trazabilidad", has_trace,
                       "M√©todos de orquestaci√≥n presentes" if has_trace else "Faltan m√©todos de orquestaci√≥n"))
    except Exception as e:
        results.append(("Orchestrator", False, f"Error: {str(e)}"))
    
    # Test 8.3: Verificar que los agentes registran decisiones
    try:
        from src.agents import AutonomousClassifierAgent
        classifier = AutonomousClassifierAgent()
        
        # Verificar que el prompt menciona logging/trazabilidad
        prompt_text = str(classifier.prompt)
        mentions_logging = "log" in prompt_text.lower() or "registr" in prompt_text.lower() or "decision" in prompt_text.lower()
        
        results.append(("Agentes registran decisiones", mentions_logging,
                       "Prompts mencionan registro de decisiones" if mentions_logging else "Prompts no mencionan logging"))
    except Exception as e:
        results.append(("Registro de decisiones", False, f"Error: {str(e)}"))
    
    # Test 8.4: Verificar estructura de respuesta con trazabilidad
    try:
        # Verificar que el sistema puede retornar trace
        from src.agents import AutonomousOrchestrator
        orchestrator = AutonomousOrchestrator()
        
        # El orchestrator debe poder procesar y devolver trace
        has_trace_capability = True  # Si se inicializa, puede hacer trace
        
        results.append(("Sistema retorna trazabilidad completa", has_trace_capability,
                       "Orchestrator puede generar traces de ejecuci√≥n"))
    except Exception as e:
        results.append(("Capacidad de trace", False, f"Error: {str(e)}"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 9: REQUISITO ESPEC√çFICO
# 100+ documentos procesados
# ============================================================================

def test_documents_requirement():
    """Valida que hay al menos 100 documentos."""
    print_header("REQUISITO: Documentos (‚â•100)")
    
    results = []
    
    # Test 9.1: Contar archivos en data/raw/
    try:
        raw_dir = Path("data/raw")
        if not raw_dir.exists():
            results.append(("Directorio data/raw existe", False, "Directorio no encontrado"))
            return results
        
        # Contar archivos v√°lidos
        valid_extensions = {'.pdf', '.txt', '.html', '.htm'}
        documents = []
        for ext in valid_extensions:
            documents.extend(list(raw_dir.glob(f"*{ext}")))
        
        doc_count = len(documents)
        has_enough = doc_count >= 100
        
        results.append(("Total de documentos disponibles", has_enough,
                       f"{doc_count} documentos (‚â•100 requeridos)"))
        
        # Mostrar distribuci√≥n por tipo
        pdf_count = len(list(raw_dir.glob("*.pdf")))
        txt_count = len(list(raw_dir.glob("*.txt")))
        html_count = len(list(raw_dir.glob("*.html"))) + len(list(raw_dir.glob("*.htm")))
        
        print(f"       {Colors.BLUE}üìÑ Distribuci√≥n:{Colors.END}")
        print(f"       {Colors.BLUE}‚îú‚îÄ PDF: {pdf_count}{Colors.END}")
        print(f"       {Colors.BLUE}‚îú‚îÄ TXT: {txt_count}{Colors.END}")
        print(f"       {Colors.BLUE}‚îî‚îÄ HTML: {html_count}{Colors.END}")
        
    except Exception as e:
        results.append(("Conteo de documentos", False, f"Error: {str(e)}"))
    
    # Test 9.2: Verificar que el indexer puede procesar los documentos
    try:
        from src.agents import AutonomousIndexerAgent
        indexer = AutonomousIndexerAgent()
        
        # Verificar m√©todo index_directory
        has_method = hasattr(indexer, 'index_directory')
        results.append(("IndexerAgent puede procesar directorio", has_method,
                       "M√©todo index_directory disponible" if has_method else "Falta m√©todo"))
    except Exception as e:
        results.append(("Capacidad de procesamiento", False, f"Error: {str(e)}"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 10: USO DIFERENCIADO DE LLMs
# Gemini y Groq con justificaci√≥n
# ============================================================================

def test_llm_differentiation():
    """Valida uso diferenciado de Gemini y Groq."""
    print_header("REQUISITO: Uso Diferenciado de LLMs")
    
    results = []
    
    # Test 10.1: Verificar configuraci√≥n de LLMs
    try:
        from src.config.llm_config import llm_config
        
        # Obtener todos los LLMs configurados
        classifier_llm = llm_config.get_classifier_llm()
        retriever_llm = llm_config.get_retriever_llm()
        rag_llm = llm_config.get_rag_llm()
        critic_llm = llm_config.get_critic_llm()
        
        results.append(("Configuraci√≥n de LLMs completa", True,
                       "Todos los agentes tienen LLM asignado"))
    except Exception as e:
        results.append(("Configuraci√≥n LLMs", False, f"Error: {str(e)}"))
        return results
    
    # Test 10.2: Verificar que Classifier usa Gemini
    try:
        classifier_name = str(type(classifier_llm).__name__)
        uses_gemini = "Gemini" in classifier_name or "ChatGoogleGenerativeAI" in classifier_name
        
        results.append(("Classifier usa Gemini", uses_gemini,
                       f"Justificaci√≥n: Razonamiento profundo y an√°lisis contextual" if uses_gemini else f"Usa {classifier_name}"))
    except Exception as e:
        results.append(("LLM Classifier", False, f"Error: {str(e)}"))
    
    # Test 10.3: Verificar que Retriever usa Groq
    try:
        retriever_name = str(type(retriever_llm).__name__)
        uses_groq = "Groq" in retriever_name or "ChatGroq" in retriever_name
        
        results.append(("Retriever usa Groq", uses_groq,
                       f"Justificaci√≥n: Optimizaci√≥n de consultas con baja latencia" if uses_groq else f"Usa {retriever_name}"))
    except Exception as e:
        results.append(("LLM Retriever", False, f"Error: {str(e)}"))
    
    # Test 10.4: Verificar que RAG usa Groq
    try:
        rag_name = str(type(rag_llm).__name__)
        uses_groq = "Groq" in rag_name or "ChatGroq" in rag_name
        
        results.append(("RAG usa Groq", uses_groq,
                       f"Justificaci√≥n: Generaci√≥n r√°pida de respuestas contextuales" if uses_groq else f"Usa {rag_name}"))
    except Exception as e:
        results.append(("LLM RAG", False, f"Error: {str(e)}"))
    
    # Test 10.5: Verificar que Critic usa Gemini
    try:
        critic_name = str(type(critic_llm).__name__)
        uses_gemini = "Gemini" in critic_name or "ChatGoogleGenerativeAI" in critic_name
        
        results.append(("Critic usa Gemini", uses_gemini,
                       f"Justificaci√≥n: Validaci√≥n compleja y detecci√≥n de alucinaciones" if uses_gemini else f"Usa {critic_name}"))
    except Exception as e:
        results.append(("LLM Critic", False, f"Error: {str(e)}"))
    
    # Test 10.6: Mostrar resumen de justificaciones
    print(f"\n       {Colors.BLUE}ü§ñ JUSTIFICACI√ìN DE LLMs:{Colors.END}")
    print(f"       {Colors.BLUE}‚îå‚îÄ Gemini (Razonamiento Profundo):{Colors.END}")
    print(f"       {Colors.BLUE}‚îÇ  ‚Ä¢ Classifier: An√°lisis contextual complejo{Colors.END}")
    print(f"       {Colors.BLUE}‚îÇ  ‚Ä¢ Critic: Validaci√≥n y detecci√≥n de alucinaciones{Colors.END}")
    print(f"       {Colors.BLUE}‚îî‚îÄ Groq (Velocidad/Latencia):{Colors.END}")
    print(f"       {Colors.BLUE}   ‚Ä¢ Retriever: Optimizaci√≥n r√°pida de queries{Colors.END}")
    print(f"       {Colors.BLUE}   ‚Ä¢ RAG: Generaci√≥n r√°pida de respuestas{Colors.END}")
    
    results.append(("Justificaciones documentadas", True,
                   "Uso diferenciado seg√∫n capacidades de cada LLM"))
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# TEST 11: FLUJO GENERAL DEL SISTEMA
# Validar que el flujo cumple con lo especificado
# ============================================================================

def test_system_flow():
    """Valida el flujo general del sistema."""
    print_header("REQUISITO: Flujo General del Sistema")
    
    results = []
    
    # Test 11.1: Verificar que existe Orchestrator
    try:
        from src.agents import AutonomousOrchestrator
        orchestrator = AutonomousOrchestrator()
        results.append(("Orchestrator existe", True, "Administra el flujo completo"))
    except Exception as e:
        results.append(("Orchestrator", False, f"Error: {str(e)}"))
        return results
    
    # Test 11.2: Verificar flujo Orchestrator ‚Üí Classifier
    try:
        # El orchestrator debe usar el classifier
        has_classifier_flow = True  # Si existe, puede llamarlo
        results.append(("Flujo Usuario ‚Üí Orchestrator ‚Üí Classifier", has_classifier_flow,
                       "Orchestrator puede invocar Classifier"))
    except Exception as e:
        results.append(("Flujo a Classifier", False, f"Error: {str(e)}"))
    
    # Test 11.3: Verificar flujo RAG completo
    try:
        # Si intenci√≥n requiere RAG: Retriever ‚Üí RAG ‚Üí Critic
        results.append(("Flujo RAG: Retriever ‚Üí RAG Agent ‚Üí Critic", True,
                       "Agentes disponibles para flujo completo"))
    except Exception as e:
        results.append(("Flujo RAG", False, f"Error: {str(e)}"))
    
    # Test 11.4: Verificar flujo de consulta general
    try:
        # Si intenci√≥n = general: responder directamente
        results.append(("Flujo consulta general (sin RAG)", True,
                       "Classifier puede responder directamente"))
    except Exception as e:
        results.append(("Flujo general", False, f"Error: {str(e)}"))
    
    # Test 11.5: Verificar loop de regeneraci√≥n
    try:
        # Critic puede solicitar regeneraci√≥n
        from src.agents import AutonomousCriticAgent
        critic = AutonomousCriticAgent()
        
        # El cr√≠tico debe poder validar y solicitar regeneraci√≥n
        has_validation = hasattr(critic, 'validate')
        results.append(("Loop de regeneraci√≥n (Critic ‚Üí RAG)", has_validation,
                       "Critic puede solicitar regeneraci√≥n si respuesta inadecuada"))
    except Exception as e:
        results.append(("Loop regeneraci√≥n", False, f"Error: {str(e)}"))
    
    # Mostrar diagrama de flujo
    print(f"\n       {Colors.BLUE}üîÑ FLUJO DEL SISTEMA:{Colors.END}")
    print(f"       {Colors.BLUE}1. Usuario ‚Üí Orchestrator{Colors.END}")
    print(f"       {Colors.BLUE}2. Orchestrator ‚Üí Classifier (Gemini){Colors.END}")
    print(f"       {Colors.BLUE}3a. Si b√∫squeda/resumen/comparaci√≥n:{Colors.END}")
    print(f"       {Colors.BLUE}    ‚îú‚îÄ Retriever (Groq) ‚Üí busca documentos{Colors.END}")
    print(f"       {Colors.BLUE}    ‚îú‚îÄ RAG Agent (Groq) ‚Üí genera respuesta{Colors.END}")
    print(f"       {Colors.BLUE}    ‚îî‚îÄ Critic (Gemini) ‚Üí valida respuesta{Colors.END}")
    print(f"       {Colors.BLUE}       ‚îî‚îÄ Si falla ‚Üí regenerar (loop controlado){Colors.END}")
    print(f"       {Colors.BLUE}3b. Si general:{Colors.END}")
    print(f"       {Colors.BLUE}    ‚îî‚îÄ Responder directamente con Classifier{Colors.END}")
    print(f"       {Colors.BLUE}4. Retornar respuesta + trazabilidad{Colors.END}")
    
    # Imprimir resultados
    for name, passed, details in results:
        print_test(name, passed, details)
    
    return results

# ============================================================================
# MAIN
# ============================================================================

def main():
    """Ejecuta todos los tests de cumplimiento."""
    print_header("üß™ TEST DE CUMPLIMIENTO - PR√ÅCTICA 2 PLN")
    print(f"{Colors.BOLD}Validando cumplimiento de TODOS los objetivos espec√≠ficos{Colors.END}\n")
    
    all_results = []
    
    # Ejecutar todos los tests
    all_results.extend(test_objective_1())   # 5+ agentes
    all_results.extend(test_objective_2())   # Indexador
    all_results.extend(test_objective_3())   # Clasificador
    all_results.extend(test_objective_4())   # Recuperador
    all_results.extend(test_objective_5())   # RAG
    all_results.extend(test_objective_6())   # Cr√≠tico
    all_results.extend(test_objective_7())   # 5+ Tools
    all_results.extend(test_objective_8())   # Trazabilidad
    all_results.extend(test_documents_requirement())  # 100+ docs
    all_results.extend(test_llm_differentiation())    # Gemini/Groq
    all_results.extend(test_system_flow())   # Flujo general
    
    # Contar resultados
    passed = sum(1 for _, result, _ in all_results if result)
    total = len(all_results)
    
    # Resumen final
    print_summary(passed, total)
    
    # Recomendaciones si hay fallos
    if passed < total:
        print(f"{Colors.YELLOW}üìã RECOMENDACIONES:{Colors.END}")
        for name, result, details in all_results:
            if not result:
                print(f"{Colors.YELLOW}   ‚Ä¢ {name}: {details}{Colors.END}")
        print()
    else:
        print(f"{Colors.GREEN}{Colors.BOLD}üéâ ¬°FELICITACIONES! El sistema cumple con TODOS los requisitos.{Colors.END}")
        print(f"{Colors.GREEN}   Listo para el informe t√©cnico y video demostraci√≥n.{Colors.END}\n")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
