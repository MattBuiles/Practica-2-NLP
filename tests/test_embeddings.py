"""
Test para EmbeddingsManager - Persona 2
Verifica que la generaci√≥n de embeddings funcione correctamente.
"""
import sys
from pathlib import Path

# Agregar src al path
sys.path.insert(0, str(Path(__file__).parent.parent))

from src.rag_pipeline.embeddings import EmbeddingsManager


def test_embeddings():
    """Prueba los componentes del EmbeddingsManager."""
    
    print("="*70)
    print("PRUEBA DE COMPONENTES - EmbeddingsManager (Persona 2)")
    print("="*70)
    
    # Test 1: Inicializaci√≥n con configuraci√≥n por defecto
    print("\n1. Probando inicializaci√≥n con configuraci√≥n por defecto...")
    try:
        embeddings_mgr = EmbeddingsManager()
        print(f"   ‚úÖ EmbeddingsManager inicializado")
        print(f"   - Modelo: {embeddings_mgr.model_name}")
        print(f"   - Dispositivo: {embeddings_mgr.device}")
        print(f"   - Dimensi√≥n: {embeddings_mgr.get_embedding_dimension()}")
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # Test 2: Verificar dependencia sentence-transformers
    print("\n2. Verificando dependencia sentence-transformers...")
    try:
        from langchain_community.embeddings import HuggingFaceEmbeddings
        print("   ‚úÖ langchain_community.embeddings.HuggingFaceEmbeddings disponible")
    except ImportError as e:
        print(f"   ‚ùå Error: {e}")
        print("   üí° Instala con: pip install sentence-transformers langchain-community")
        return
    
    # Test 3: Generar embedding de un texto simple
    print("\n3. Probando generaci√≥n de embedding de texto simple...")
    try:
        test_text = "Los dinosaurios fueron reptiles que dominaron la Tierra durante millones de a√±os."
        embedding = embeddings_mgr.embed_text(test_text)
        
        print(f"   ‚úÖ Embedding generado")
        print(f"   - Dimensi√≥n del embedding: {len(embedding)}")
        print(f"   - Tipo: {type(embedding)}")
        print(f"   - Primeros 5 valores: {embedding[:5]}")
        
        # Verificar dimensi√≥n
        expected_dim = embeddings_mgr.get_embedding_dimension()
        if len(embedding) == expected_dim:
            print(f"   ‚úÖ Dimensi√≥n correcta ({expected_dim})")
        else:
            print(f"   ‚ö†Ô∏è  Dimensi√≥n esperada: {expected_dim}, obtenida: {len(embedding)}")
        
        # Verificar que no es todo ceros
        if any(abs(val) > 0.001 for val in embedding):
            print(f"   ‚úÖ Embedding contiene valores no nulos")
        else:
            print(f"   ‚ö†Ô∏è  Embedding parece estar vac√≠o o ser todo ceros")
            
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 4: Generar embeddings de m√∫ltiples textos (batch)
    print("\n4. Probando generaci√≥n de embeddings en batch...")
    try:
        test_texts = [
            "Los dinosaurios fueron reptiles que dominaron la Tierra.",
            "El Tyrannosaurus rex era un depredador temible.",
            "Los triceratops ten√≠an tres cuernos en su cabeza."
        ]
        
        embeddings = embeddings_mgr.embed_texts(test_texts)
        
        print(f"   ‚úÖ Embeddings generados en batch")
        print(f"   - Textos procesados: {len(test_texts)}")
        print(f"   - Embeddings generados: {len(embeddings)}")
        
        if len(embeddings) == len(test_texts):
            print(f"   ‚úÖ N√∫mero de embeddings coincide con n√∫mero de textos")
        else:
            print(f"   ‚ö†Ô∏è  N√∫mero de embeddings no coincide")
        
        # Verificar que todos tienen la misma dimensi√≥n
        dims = [len(emb) for emb in embeddings]
        if len(set(dims)) == 1:
            print(f"   ‚úÖ Todos los embeddings tienen la misma dimensi√≥n: {dims[0]}")
        else:
            print(f"   ‚ö†Ô∏è  Embeddings con dimensiones diferentes: {dims}")
            
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 5: Embeddings de documentos
    print("\n5. Probando generaci√≥n de embeddings para documentos...")
    try:
        test_docs = [
            {
                'content': 'Los dinosaurios fueron un grupo diverso de reptiles.',
                'metadata': {'source': 'doc1.txt', 'file_path': '/data/doc1.txt'}
            },
            {
                'content': 'El Tyrannosaurus rex era uno de los carn√≠voros m√°s grandes.',
                'metadata': {'source': 'doc2.txt', 'file_path': '/data/doc2.txt'}
            }
        ]
        
        docs_with_embeddings = embeddings_mgr.embed_documents(test_docs)
        
        print(f"   ‚úÖ Embeddings generados para documentos")
        print(f"   - Documentos procesados: {len(test_docs)}")
        print(f"   - Documentos con embeddings: {len(docs_with_embeddings)}")
        
        if docs_with_embeddings:
            first_doc = docs_with_embeddings[0]
            print(f"\n   üìã Estructura del primer documento:")
            print(f"   - Tiene 'content': {'content' in first_doc}")
            print(f"   - Tiene 'metadata': {'metadata' in first_doc}")
            print(f"   - Tiene 'embedding': {'embedding' in first_doc}")
            print(f"   - Dimensi√≥n del embedding: {len(first_doc.get('embedding', []))}")
            print(f"   - Metadata preservada: {first_doc['metadata'].get('source', 'N/A')}")
            
            if 'embedding' in first_doc and len(first_doc['embedding']) > 0:
                print(f"   ‚úÖ Embedding agregado correctamente al documento")
            else:
                print(f"   ‚ö†Ô∏è  Embedding no encontrado o vac√≠o")
                
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 6: Verificar similitud entre textos relacionados
    print("\n6. Probando similitud sem√°ntica entre textos relacionados...")
    try:
        import numpy as np
        
        text1 = "Los dinosaurios eran reptiles prehist√≥ricos."
        text2 = "Los dinosaurios fueron animales que vivieron hace millones de a√±os."
        text3 = "La programaci√≥n en Python es muy popular."
        
        emb1 = embeddings_mgr.embed_text(text1)
        emb2 = embeddings_mgr.embed_text(text2)
        emb3 = embeddings_mgr.embed_text(text3)
        
        # Calcular similitud coseno (los embeddings est√°n normalizados)
        similarity_1_2 = np.dot(emb1, emb2)  # Cosine similarity (normalizados)
        similarity_1_3 = np.dot(emb1, emb3)
        
        print(f"   ‚úÖ Similitudes calculadas")
        print(f"   - Similitud (texto1, texto2): {similarity_1_2:.4f}")
        print(f"   - Similitud (texto1, texto3): {similarity_1_3:.4f}")
        
        if similarity_1_2 > similarity_1_3:
            print(f"   ‚úÖ Textos relacionados tienen mayor similitud")
        else:
            print(f"   ‚ö†Ô∏è  Similitud inesperada (puede ser normal seg√∫n el modelo)")
            
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 7: Manejo de textos vac√≠os
    print("\n7. Probando manejo de textos vac√≠os...")
    try:
        empty_text = ""
        whitespace_text = "   \n\t  "
        
        emb_empty = embeddings_mgr.embed_text(empty_text)
        emb_whitespace = embeddings_mgr.embed_text(whitespace_text)
        
        print(f"   ‚úÖ Manejo de textos vac√≠os")
        print(f"   - Embedding de texto vac√≠o: dimensi√≥n {len(emb_empty)}")
        print(f"   - Embedding de solo espacios: dimensi√≥n {len(emb_whitespace)}")
        
        # Verificar que son vectores de ceros
        if all(abs(val) < 0.001 for val in emb_empty):
            print(f"   ‚úÖ Texto vac√≠o genera vector de ceros")
        else:
            print(f"   ‚ö†Ô∏è  Texto vac√≠o no genera vector de ceros")
            
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 8: Verificar normalizaci√≥n de embeddings
    print("\n8. Verificando normalizaci√≥n de embeddings...")
    try:
        import numpy as np
        
        test_text = "Los dinosaurios fueron animales fascinantes."
        embedding = embeddings_mgr.embed_text(test_text)
        
        # Calcular norma del vector
        norm = np.linalg.norm(embedding)
        
        print(f"   ‚úÖ Verificaci√≥n de normalizaci√≥n")
        print(f"   - Norma del embedding: {norm:.6f}")
        
        # Los embeddings deber√≠an estar normalizados (norma ‚âà 1.0)
        if abs(norm - 1.0) < 0.01:
            print(f"   ‚úÖ Embedding est√° normalizado (norma ‚âà 1.0)")
        else:
            print(f"   ‚ö†Ô∏è  Embedding no est√° normalizado (norma = {norm:.6f})")
            
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    # Test 9: Instancia global
    print("\n9. Verificando instancia global...")
    try:
        from src.rag_pipeline.embeddings import embeddings_manager
        
        print(f"   ‚úÖ Instancia global disponible")
        print(f"   - Tipo: {type(embeddings_manager)}")
        print(f"   - Modelo: {embeddings_manager.model_name}")
        
        # Probar que funciona
        test_emb = embeddings_manager.embed_text("Test")
        print(f"   ‚úÖ Instancia global funcional (dimensi√≥n: {len(test_emb)})")
        
    except Exception as e:
        print(f"   ‚ùå Error: {e}")
        import traceback
        traceback.print_exc()
    
    # Resumen
    print("\n" + "="*70)
    print("RESUMEN DE PRUEBAS")
    print("="*70)
    
    print("\n‚úÖ COMPONENTES IMPLEMENTADOS (EmbeddingsManager):")
    print("   1. Inicializaci√≥n con configuraci√≥n por defecto")
    print("   2. Dependencia sentence-transformers verificada")
    print("   3. Generaci√≥n de embedding de texto simple")
    print("   4. Generaci√≥n de embeddings en batch")
    print("   5. Generaci√≥n de embeddings para documentos")
    print("   6. Verificaci√≥n de similitud sem√°ntica")
    print("   7. Manejo de textos vac√≠os")
    print("   8. Verificaci√≥n de normalizaci√≥n")
    print("   9. Instancia global")
    
    print("\n‚úÖ ESTADO: EmbeddingsManager funcionando correctamente")
    
    print("\n" + "="*70)


if __name__ == "__main__":
    test_embeddings()

